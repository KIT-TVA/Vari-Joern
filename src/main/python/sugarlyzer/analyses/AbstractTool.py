import functools
import logging
import operator
import shutil
import time
from abc import ABC, abstractmethod
from hashlib import sha256
from pathlib import Path
from typing import Iterable, List

from python.sugarlyzer.models.alarm.Alarm import Alarm
from python.sugarlyzer.readers.AbstractReader import AbstractReader

logger = logging.getLogger(__name__)


class AbstractTool(ABC):
    """
    Abstract base class for SAST-tools that should be available through Sugarlyzer.
    """

    def __init__(self,
                 reader: AbstractReader,
                 name: str,
                 keep_mem: bool,
                 make_main: bool,
                 remove_errors: bool,
                 intermediary_results_path: Path,
                 results_cache: Path = None,
                 desugaring_function_whitelist: List[str] = None):
        """
        Constructs a new instance.

        :param reader: An instance of the AbstractReader class that should be used to read the report files created by
        the tool and produce corresponding alarms.
        :param name: The name of the tool.
        :param keep_mem: Boolean flag specifying whether memory related functions (e.g., malloc, free) should be
        excluded from renaming during desugaring by SugarC.
        :param make_main: Boolean flag specifying whether a main function should be incorporated into the desugared
        source file.
        :param remove_errors: TODO
        :param intermediary_results_path: A path specifying the location at which intermediary results of the tool
        should be stored.
        :param results_cache: A path specifying the directory in which report files of the tool should be cached.
        :param desugaring_function_whitelist: A list of function identifiers that should be excluded from renaming
        during desugaring by SugarC.
        """

        self.reader = reader
        self.keep_mem = keep_mem,
        self.make_main = make_main
        self.remove_errors = remove_errors
        self.name = name
        self.results_dir = intermediary_results_path
        self.cache_dir = results_cache

        self.desugaring_function_whitelist = [] if desugaring_function_whitelist is None \
            else desugaring_function_whitelist

    def analyze_file_and_read_alarms(self,
                                     desugared_source_file: Path,
                                     unpreprocessed_source_file: Path,
                                     command_line_defs: Iterable[str] = None,
                                     included_dirs: Iterable[Path] = None,
                                     included_files: Iterable[Path] = None) -> Iterable[Alarm]:
        """
        Analyzes a desugared .c file, and returns the alarms that were generated by applying the SAST tool.

        :param desugared_source_file: The desugared source file that should be analyzed.
        :param unpreprocessed_source_file: The unpreprocessed source file from which the desugared source file was
        generated.
        :param command_line_defs: Macro (un)definitions that should be set for the analysis.
        :param included_dirs: Directories that should be used by the analysis tool (e.g., to search for headers).
        :param included_files: Files that should be used as includes by the analysis tool (e.g., macro definitions
        in separate header files).
        :return: A collection of alarms reported by the analysis tool.
        """
        start_time: float = time.monotonic()

        # Check cache for existing reports for the specific file.
        cache_dir_hits: list[Path] | None = None
        hex_hash: str | None = None
        if self.cache_dir is not None:
            # Build hash.
            hasher = sha256()

            with open(file=desugared_source_file, mode="r") as file:
                for line in file:
                    hasher.update(bytes(line, 'utf-8'))
            for command_line_def in sorted(command_line_defs or []):
                hasher.update(bytes(command_line_def, 'utf-8'))
            for included_dir in sorted(included_dirs or []):
                hasher.update(bytes(str(included_dir), 'utf-8'))
            for included_file in sorted(included_files or []):
                hasher.update(bytes(str(included_file), 'utf-8'))

            hex_hash: str = hasher.hexdigest()
            cache_dir_hits = list(self.cache_dir.glob(pattern=f"{self.name}_report_{desugared_source_file.name}_{hex_hash}*"))

        cache_hit: bool = (cache_dir_hits is not None) and (len(list(cache_dir_hits)) > 0)

        # Run analysis tool (or se results collected from cache directory).
        tool_report_files: list[Path] = [] # There could be multiple report files for a single source file.
        if cache_hit:
            logger.debug(f"Cache hit for analysis results of file {str(desugared_source_file)}")
            tool_report_files = cache_dir_hits
        else:
            logger.debug(f"Cache miss for file {str(desugared_source_file)}. Running {self.name}...")
            tool_report_files = list(self.analyze(desugared_source_file=desugared_source_file,
                                                  command_line_defs=command_line_defs,
                                                  included_dirs=included_dirs,
                                                  included_files=included_files))

        # Add new entries to cache.
        if self.cache_dir is not None and not cache_hit:
            # Ensure that the cache folder exists.
            self.cache_dir.mkdir(parents=True, exist_ok=True)

            index: int = 1
            for tool_report_file in tool_report_files:
                shutil.copy(src=tool_report_file, dst=self.cache_dir / Path(
                    f"{self.name}_report_{desugared_source_file.name}_{hex_hash}_{index}{tool_report_file.suffix}"))
                index += 1

        # Read output created by the analysis tool and collect all the resulting alarm objects in a single list.
        alarms: Iterable[Alarm] = \
            functools.reduce(operator.iconcat, [
                self.reader.read_output(report_file=report_file,
                                        desugared_source_file=desugared_source_file,
                                        unpreprocessed_source_file=unpreprocessed_source_file) for report_file in
                tool_report_files], [])

        total_time: float = time.monotonic() - start_time
        logger.info(f"Analyzing file {desugared_source_file} took {total_time}s ({'Cache Hit' if cache_hit else 'Cache Miss'})")

        for a in alarms:
            a.analysis_time = total_time

        return alarms

    @abstractmethod
    def analyze(self,
                desugared_source_file: Path,
                included_dirs: Iterable[Path] = None,
                included_files: Iterable[Path] = None,
                command_line_defs: Iterable[str] = None) -> Iterable[Path]:
        """
        Analyzes a file and returns the locations of the resulting reports created by the analysis tool.

        :param desugared_source_file: The desugared file to which the analysis tool should be applied.
        :param included_dirs: The directory includes that should be passed to the tool.
        :param included_files: The file includes that should be passed to the tool.
        :param command_line_defs: The command line definitions that should be passed to the tool.
        :return: The output report files produced by running the tool on the desugared source file.
        """
        pass
